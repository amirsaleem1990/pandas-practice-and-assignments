def partition(x):
    if x < 3:
        return 'positive'
    return 'negative'

column = cv['column']
t = column.map(partition)
df["new_column"]=t

--------------------------------------------------
# remove duplicates from specific columns

df = df.drop_duplicates(subset={"column1","column2","column3","column4"})
--------------------------------------------------
# is all values in particuler column is uqique or not?
df['column].is_unique
# True / False
--------------------------------------------------
# df slicing
# in <column> from 1905 to 1906
df.loc[1905:, 'column'].head(10)
--------------------------------------------------
# column to numeric
df['column'] = pd.to_numeric(df['column'])
-------------------------------------------------
>>> pub = df['column']
>>> london = pub.str.contains('London')
>>> london[:5]
Identifier
206    True
216    True
218    True
472    True
480    True
Name: Place of Publication, dtype: bool

>>> oxford = pub.str.contains('Oxford')
df['column'] = np.where(london, 'London',
                                      np.where(oxford, 'Oxford',
                                               pub.str.replace('-', ' ')))

>>> df['column'].head()
Identifier
206    London
216    London
218    London
472    London
480    London
Name: Place of Publication, dtype: object
---------------------------------------------------
# rename one column name among all columns
df.rename(columns = {'column_x' : 'column_y'}, inplace=True)
# rename more than one columns names amont all columns
new_names = {'1' : 'column_1', '5' : 'column_5'}
df.reanem(column = new_names, inplace = True)
--------------------------------------------------
# Dropping rows having NULL Values
df.dropna(inplace=True)
--------------------------------------------------
df = pd.read_csv("file.csv", encoding = "ISO-8859-1", error_bad_lines=False)
--------------------------------------------------
# all columns and qty of null values in each column
df.isnull().sum()
--------------------------------------------------
# variables Qty that contain null values 
df.isnull().sum().sum()
--------------------------------------------------
# unique items Qty.
df.column.nunique()
-------------------------------------------------
# get grops sizes
df.groupby('column').size().reset_index(name='Enter new name for column')
# another 
df.groupby('column').count()
-------------------------------------------------
# entire column to lower case
df['column'] = df['column'].str.lower()
-------------------------------------------------
# string me jagan bhi <https> ho to us  k baad agly space tak sab remove kar do
import re
df[column] = df[column].apply(lambda i: re.sub(r"http\S+", "", i))
-------------------------------------------------
# all null values from all variables 
df.isnull().sum()
-------------------------------------------------
# can sort by values too
df.sort_values(by='B')
-------------------------------------------------
# column slicing
df.iloc[:,1:3]
-------------------------------------------------
# all rows and partuculer columns
# column slicing
df.iloc[:,1:3]
-------------------------------------------------
# filtering
df3 = df.copy()
df3['E'] = ['one', 'one', 'two', 'three', 'four', 'three']
# srif wo rows jin k <E> column me <two> ya <four> h
df3[df3['E'].isin(['two', 'four'])]
-------------------------------------------------
# index me jahan bhi <amir> h us k <A> column me <0> kar do
df.at['amir','A'] = 0
-------------------------------------------------
# index me 'amir' or 'noman' k darmyan jo bhi rows hen un k column <E> ki value ko <1> kar do
df.loc['amir':'noman','E'] = 1
-------------------------------------------------
# drop rows with missing data
# agar ksi row ki koi value bhi <NA> ya <NaN> h to us poori row ko drop kar do
df.dropna(how='any')
-------------------------------------------------
# fill missing data
# sab missing values ko <5> me <5> fill kar do
df4.fillna(value=5)
-------------------------------------------------
# column vise mean
df.mean()
-------------------------------------------------
# pivot the mean calculation
# row vise mean # ignoring non numarical values
df.mean(1)
-------------------------------------------------
# <min> and <max> for all variables
df.apply(lambda x: (x.max(), x.min()))
-------------------------------------------------
# concatenation
pd.concat([df1, df2, df3, df4])
-------------------------------------------------
# group by
df.groupby('A').sum()
df.groupby('A').count()
-------------------------------------------------
scipy.sparse.csr_matrix to nd.array

type(count_train)
# scipy.sparse.csr.csr_matrix
new = count_train.A
type(new)
# numpy.ndarray
-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------
-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------
-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------
-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------
-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------

-------------------------------------------------
